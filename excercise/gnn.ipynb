{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
    "import torch\n",
    "\n",
    "TORCH, CUDA = torch.__version__.split('+')\n",
    "\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-geometric gdown sklearn matplotlib networkx rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gdown\n",
    "from torch_geometric.data import InMemoryDataset, Data, Batch\n",
    "\n",
    "class CosmicRayDS(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"cr_sphere.npz\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        url = \"https://drive.google.com/u/0/uc?export=download&confirm=HgGH&id=1XKN-Ik7BDyMWdQ230zWS2bNxXL3_9jZq\"\n",
    "        if os.path.exists(self.raw_file_names[0]) == False:\n",
    "            gdown.download(url, self.raw_file_names[0], quiet=True)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(self.raw_file_names[0])\n",
    "        x = torch.tensor(f[\"data\"]).float()\n",
    "        y = torch.tensor(f[\"label\"]).float()\n",
    "        data_list = []\n",
    "        for idx in range(len(x)):\n",
    "            data_list.append(\n",
    "                Data(x=x[idx, :, 3].reshape(-1, 1), pos=x[idx, :, :3], y=y[idx])\n",
    "            )\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "ds = CosmicRayDS(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Graph Handling\n",
    " For this exercise we will learn to use `pytorch_geometric` (PyG) to run GNNs.\n",
    " The library comes with a comprehensive [documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html) and not only provides tools to handle graphs but also provides a large set of GNN specific layers and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 1.1\n",
    " [Data Handling of Graphs](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs) offers a nice introduction into handling graphs.\n",
    " Provide an adjacency matric for cyclic graph (each nodes connects to the next) with 5 nodes. Convert the adjacency matric to an edge_index using `dense_to_sparse`. With this edge_index implement a graph with features [0,1,...,n-1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "adj = torch.tensor(\n",
    "    [\n",
    "        [0.0, 1.0, ?, ?, ?],\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "\n",
    "cycle = Data(\n",
    "    x=...\n",
    "    edge_index=...dense_to_sparse(...)[0],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 1.2\n",
    " Implement binary tree with 7 nodes over three levels directly constructing the edge_index.:\n",
    "    0\n",
    "  1   2\n",
    " 3 4 5 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Data(\n",
    "    x=...,\n",
    "    edge_index=torch.tensor([[0, 1], ...]).T,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 1.3\n",
    " Convert the implemented PyG graphs to `networkx` graphs and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "nx.draw_kamada_kawai(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_kamada_kawai(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 1.4\n",
    " Have a look at the documentation on [Mini-batches](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#mini-batches).\n",
    "\n",
    " Batch the two graphs together and plot the batch with networkx. What do you see ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch.from_data_list(...)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 1.5\n",
    " Inspect the properties of the batch.\n",
    " You can use the `inspect` method of the rich library or a simple `print`.\n",
    " What do the `batch` and `ptr` attributes do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "rich.inspect(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adapted from https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2 Introduction: Hands-on Graph Neural Networks\n",
    "\n",
    " Recently, deep learning on graphs has emerged to one of the hottest research fields in the deep learning community.\n",
    " Here, **Graph Neural Networks (GNNs)** aim to generalize classical deep learning concepts to irregular structured data (in contrast to images or texts) and to enable neural networks to reason about objects and their relations.\n",
    "\n",
    " This is done by following a simple **neural message passing scheme**, where node features $\\mathbf{x}_v^{(\\ell)}$ of all nodes $v \\in \\mathcal{V}$ in a graph $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ are iteratively updated by aggregating localized information from their neighbors $\\mathcal{N}(v)$:\n",
    "\n",
    " $$\n",
    " \\mathbf{x}_v^{(\\ell + 1)} = f^{(\\ell + 1)}_{\\theta} \\left( \\mathbf{x}_v^{(\\ell)}, \\left\\{ \\mathbf{x}_w^{(\\ell)} : w \\in \\mathcal{N}(v) \\right\\} \\right)\n",
    " $$\n",
    "\n",
    " This tutorial will introduce you to some fundamental concepts regarding deep learning on graphs via Graph Neural Networks based on the **[PyTorch Geometric (PyG) library](https://github.com/rusty1s/pytorch_geometric)**.\n",
    " PyTorch Geometric is an extension library to the popular deep learning framework [PyTorch](https://pytorch.org/), and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n",
    "\n",
    " Following [Kipf et al. (2017)](https://arxiv.org/abs/1609.02907), let's dive into the world of GNNs by looking at a simple graph-structured example, the well-known [**Zachary's karate club network**](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). This graph describes a social network of 34 members of a karate club and documents links between members who interacted outside the club. Here, we are interested in detecting communities that arise from the member's interaction.\n",
    "\n",
    " PyTorch Geometric provides an easy access to this dataset via the [`torch_geometric.datasets`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets) subpackage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "dataset = KarateClub()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After initializing the [`KarateClub`](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClub) dataset, we first can inspect some of its properties.\n",
    " For example, we can see that this dataset holds exactly **one graph**, and that each node in this dataset is assigned a **34-dimensional feature vector** (which uniquely describes the members of the karate club).\n",
    " Furthermore, the graph holds exactly **4 classes**, which represent the community each node belongs to.\n",
    "\n",
    " Let's now look at the underlying graph in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Each graph in PyTorch Geometric is represented by a single [`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) object, which holds all the information to describe its graph representation.\n",
    " We can print the data object anytime via `print(data)` to receive a short summary about its attributes and their shapes:\n",
    " ```\n",
    " Data(edge_index=[2, 156], x=[34, 34], y=[34], train_mask=[34])\n",
    " ```\n",
    " We can see that this `data` object holds 4 attributes:\n",
    " 1. The `edge_index` property holds the information about the **graph connectivity**, *i.e.*, a tuple of source and destination node indices for each edge.\n",
    " 2. The **node features** `x` (each of the 34 nodes is assigned a 34-dim feature vector)\n",
    " 3. The **node labels**  `y` (each node is assigned to exactly one class).\n",
    " 4. There also exists an additional attribute called `train_mask`, which describes for which nodes we already know their community assigments.\n",
    " In total, we are only aware of the ground-truth labels of 4 nodes (one for each community), and the task is to infer the community assignment for the remaining nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 2.1\n",
    " Plot the network graph.\n",
    " Color the nodes according to their class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "nx.draw_networkx( ..., node_color=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 2.2 - Implementing Graph Neural Networks\n",
    "\n",
    " After learning about PyG's data handling, it's time to implement our first Graph Neural Network!\n",
    "\n",
    " For this, we will use on of the most simple GNN operators, the **GCN layer** ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)), which is defined as\n",
    "\n",
    " $$\n",
    " \\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n",
    " $$\n",
    "\n",
    " where $\\mathbf{W}^{(\\ell + 1)}$ denotes a trainable weight matrix of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge.\n",
    "\n",
    " PyG implements this layer via [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv), which can be executed by passing in the node feature representation `x` and the COO graph connectivity representation `edge_index`.\n",
    "\n",
    " With this, we are ready to create our first Graph Neural Network by defining our network architecture in a `torch.nn.Module` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = Linear(2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, we first initialize all of our building blocks in `__init__` and define the computation flow of our network in `forward`.\n",
    " We first define and stack **three graph convolution layers**, which corresponds to aggregating 3-hop neighborhood information around each node (all nodes up to 3 \"hops\" away).\n",
    " In addition, the `GCNConv` layers reduce the node feature dimensionality to $2$, *i.e.*, $34 \\rightarrow 4 \\rightarrow 4 \\rightarrow 2$. Each `GCNConv` layer is enhanced by a [tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html?highlight=tanh#torch.nn.Tanh) non-linearity.\n",
    "\n",
    " After that, we apply a single linear transformation ([`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear)) that acts as a classifier to map our nodes to 1 out of the 4 classes/communities.\n",
    "\n",
    " We return both the output of the final classifier as well as the final node embeddings produced by our GNN.\n",
    " We proceed to initialize our final model via `GCN()`, and printing our model produces a summary of all its used sub-modules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Embedding the Karate Club Network\n",
    "\n",
    " Let's take a look at the node embeddings produced by our GNN before training it.\n",
    " Pass in the initial node features `x` and the graph connectivity information `edge_index` to the model, and visualize its 2-dimensional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "model = GCN()\n",
    "\n",
    "embedding= ...\n",
    "visualize_embedding(embedding, color=data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Remarkably, even before training the weights of our model, the model produces an embedding of nodes that closely resembles the community-structure of the graph.\n",
    " Nodes of the same color (community) are already closely clustered together in the embedding space, although the weights of our model are initialized **completely at random** and we have not yet performed any training so far!\n",
    " This leads to the conclusion that GNNs introduce a strong inductive bias, leading to similar embeddings for nodes that are close to each other in the input graph.\n",
    "\n",
    " ## Task 2.3 Training on the Karate Club Network\n",
    "\n",
    " But can we do better? Let's look at an example on how to train our network parameters based on the knowledge of the community assignments of 4 nodes in the graph (one for each community):\n",
    "\n",
    " Since everything in our model is differentiable and parameterized, we can add some labels, train the model and observe how the embeddings react.\n",
    " Here, we make use of a semi-supervised or transductive learning procedure: We simply train against one node per class, but are allowed to make use of the complete input graph data.\n",
    "\n",
    " Training our model is very similar to any other PyTorch model.\n",
    " In addition to defining our network architecture, we define a loss critertion (here, [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) and initialize a stochastic gradient optimizer (here, [`Adam`](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam)).\n",
    " After that, we perform multiple rounds of optimization, where each round consists of a forward and backward pass to compute the gradients of our model parameters w.r.t. to the loss derived from the forward pass.\n",
    "\n",
    "\n",
    " Note that our semi-supervised learning scenario is achieved by the following line:\n",
    " ```\n",
    " loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    " ```\n",
    " While we compute node embeddings for all of our nodes, we **only make use of the training nodes for computing the loss**.\n",
    " Here, this is implemented by filtering the output of the classifier `out` and ground-truth labels `data.y` to only contain the nodes in the `train_mask`.\n",
    "\n",
    " Let us now start training and see how our node embeddings evolve over time (best experienced by explicitely running the code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 430})'''))\n",
    "\n",
    "model = GCN()\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer.\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(401):\n",
    "    loss, h = train(data)\n",
    "    if epoch % 100 == 0:\n",
    "        visualize_embedding(h, color=data.y, epoch=epoch, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What do you notice when looking at the embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adapted from https://github.com/DeepLearningForPhysicsResearchBook/deep-learning-physics/blob/main/Exercise_10_1.ipynb\n",
    " ## 3 Signal Classification using Dynamic Graph Convolutional Neural Networks\n",
    " After a long journey through the universe before reaching the earth, the cosmic particles interact with the galactic magnetic field $B$.\n",
    " As these particles carry a charge $q$ they are deflected in the field by the Lorentz force $F = q \\cdot v Ã— B$.\n",
    " Sources of cosmic particles are located all over the sky, thus arrival distributions of the cosmic particles are isotropic in general. However, particles originating from the same source generate on top of the isotropic\n",
    " arrival directions, street-like patterns from galactic magnetic field deflections.\n",
    "\n",
    " In this tasks we want to classify whether a simulated set of $500$ arriving cosmic particles contains street-like patterns (signal), or originates from an isotropic background.\n",
    "\n",
    " Training graph networks can be computationally demanding, thus, we recommend to use a GPU for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils import CosmicRayDS\n",
    "\n",
    "ds = CosmicRayDS(\".\")\n",
    "n_test = 10000\n",
    "ds_train, ds_test = ds[:-n_test], ds[-n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.1\n",
    " Extract a single event from the test dataset and inspect it.\n",
    " Plot an example sky map using the `skymap` function from `utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import skymap\n",
    "event0= ...\n",
    "fig = skymap(..., c=event0.x, zlabel=\"Energy (normed)\", title=\"Event 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.2\n",
    " Generate edges for the event using `knn_graph`.\n",
    " Plot the edges by passing the `edge_index` to the `skymap` function. How does the number of edges scale with the $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "\n",
    "fig = skymap(\n",
    "    ...,\n",
    "    c=...,\n",
    "    edge_index=...,\n",
    "    zlabel=\"Energy (normed)\",\n",
    "    title=\"Event 0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3\n",
    "Write a class to return a simple Feed-Forward-Network (FFN) for a given number inputs and outputs. (3 layers, 20 hidden nodes, BatchNorm, LeakyReLU)\n",
    "The final layer has neither activation nor norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_in, n_out, n_hidden=20):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            ...\n",
    "        )\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.seq(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.4\n",
    " GNNs classifiers are frequently build in a two step process: First MessagePassingLayers( aka Graph [Convolutional Layers](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers) ) update the nodes. These exploit the local information. Then, the nodes are aggregated using [Pooling Layers](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#pooling-layers), reducing the graph to a single feature vector. This feature vector is then passed through a FFN to get the classification output.\n",
    " Have a look at the documentation of [EdgeConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.EdgeConv) and [DynamicEdgeConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.DynamicEdgeConv).\n",
    " What is the difference?\n",
    " -> `EdgeConv` requires a `edge_index` while `DynamicEdgeConv` constructs the `edge_index` on the feature space.\n",
    " What the input space of the `nn` passed to EdgeConv?\n",
    " -> 2* num_features\n",
    " Implement a GNN class with three MPL (not MLP!) using EdgeConv\n",
    " and DynamicEdgeConv. For the first MPL, we want to construct\n",
    " the `edge_index` on the feature space.\n",
    " Use both the energies of the particles (`batch.x`) as well as their positions (`batch.pos`) as an input to the first MPL.\n",
    " For the other two layer we may (or may not) choose to construct the `edge_index` on the feature space.\n",
    " > Sidenote: Running `knn` multiple times per forward-pass might be quite expensive, depending on the number of nodes and the dimensionality of the space.\n",
    " After the MPLs apply a `global_X_pool` and pass the result through a FFN projecting to a single node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph, EdgeConv, DynamicEdgeConv, global_add_pool\n",
    "\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = ...\n",
    "\n",
    "    def forward(self, batch: Batch):\n",
    "        # We run knn on the positions\n",
    "        # knn needs to know about the batches, otherwise it connects\n",
    "        # points from different events\n",
    "        edge_index = ...\n",
    "        x = torch.hstack([batch.x, batch.pos])\n",
    "        ...\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.5\n",
    " Fill in  the gaps to implement a training loop.\n",
    " > The [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html) is recommended as it combines a Sigmoid layer and the `BCELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "loader = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
    "model = GNN().to(device)\n",
    "optim = ...\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for iepoch in range(?):\n",
    "    for batch in tqdm(loader):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.6\n",
    " Collect the outputs for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(ds_test, batch_size=64, shuffle=True)\n",
    "model.eval()\n",
    "output_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader):\n",
    "        ...\n",
    "ytrue, yhat = torch.hstack(output_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.7\n",
    " Evalutate the model performance on the test set by computing the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task 3.8 - Bonus/Open end\n",
    " Optimize the model for AUC and speed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf1e7457895ee7dafed1f4a11df8662f6860406cb300c73c45b696a5411f164d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
