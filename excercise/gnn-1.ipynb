{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mscham/deep-learning-physics/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","Requirement already satisfied: torch-scatter in ./venv/lib/python3.8/site-packages (2.0.9)\n","\u001b[33mWARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n","You should consider upgrading via the '/home/mscham/deep-learning-physics/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","Requirement already satisfied: torch-sparse in ./venv/lib/python3.8/site-packages (0.6.15)\n","Requirement already satisfied: scipy in ./venv/lib/python3.8/site-packages (from torch-sparse) (1.9.3)\n","Requirement already satisfied: numpy<1.26.0,>=1.18.5 in ./venv/lib/python3.8/site-packages (from scipy->torch-sparse) (1.23.5)\n","\u001b[33mWARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n","You should consider upgrading via the '/home/mscham/deep-learning-physics/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","Requirement already satisfied: torch-cluster in ./venv/lib/python3.8/site-packages (1.6.0)\n","\u001b[33mWARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n","You should consider upgrading via the '/home/mscham/deep-learning-physics/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n","Requirement already satisfied: torch-spline-conv in ./venv/lib/python3.8/site-packages (1.2.1)\n","\u001b[33mWARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n","You should consider upgrading via the '/home/mscham/deep-learning-physics/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n","Requirement already satisfied: torch-geometric in ./venv/lib/python3.8/site-packages (2.1.0.post1)\n","Requirement already satisfied: matplotlib in ./venv/lib/python3.8/site-packages (3.6.2)\n","Requirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (2.8.8)\n","Requirement already satisfied: rich in ./venv/lib/python3.8/site-packages (12.6.0)\n","Requirement already satisfied: tqdm in ./venv/lib/python3.8/site-packages (from torch-geometric) (4.64.1)\n","Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from torch-geometric) (1.23.5)\n","Requirement already satisfied: scipy in ./venv/lib/python3.8/site-packages (from torch-geometric) (1.9.3)\n","Requirement already satisfied: jinja2 in ./venv/lib/python3.8/site-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in ./venv/lib/python3.8/site-packages (from torch-geometric) (2.28.1)\n","Requirement already satisfied: pyparsing in ./venv/lib/python3.8/site-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in ./venv/lib/python3.8/site-packages (from torch-geometric) (1.1.3)\n","Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (4.38.0)\n","Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.0.6)\n","Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (9.3.0)\n","Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib) (21.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in ./venv/lib/python3.8/site-packages (from rich) (2.13.0)\n","Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in ./venv/lib/python3.8/site-packages (from rich) (0.9.1)\n","Requirement already satisfied: typing-extensions<5.0,>=4.0.0; python_version < \"3.9\" in ./venv/lib/python3.8/site-packages (from rich) (4.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests->torch-geometric) (1.26.12)\n","Requirement already satisfied: charset-normalizer<3,>=2 in ./venv/lib/python3.8/site-packages (from requests->torch-geometric) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests->torch-geometric) (2022.9.24)\n","Requirement already satisfied: joblib>=1.0.0 in ./venv/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","\u001b[33mWARNING: You are using pip version 20.2.1; however, version 22.3.1 is available.\n","You should consider upgrading via the '/home/mscham/deep-learning-physics/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n","import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric matplotlib networkx rich"]},{"cell_type":"markdown","metadata":{},"source":[" # Graph Handling\n"," For this exercise we will learn to use `pytorch_geometric` (PyG) to run GNNs.\n"," The library comes with a comprehensive [documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html) and not only provides tools to handle graphs but also provides a large set of GNN specific layers and dataset."]},{"cell_type":"markdown","metadata":{},"source":[" ## Task 1.1\n"," [Data Handling of Graphs](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs) offers a nice introduction into handling graphs.\n"," Provide an adjacency matric for cyclic graph (each nodes connects to the next) with 5 nodes. Convert the adjacency matric to an edge_index. With this edge_index implement a graph with features [0,1,...,n-1]:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch_geometric.data import Data, Batch\n","from torch_geometric.utils import dense_to_sparse\n","\n","adj = torch.tensor(\n","    [\n","        [0.0, 0.0, 0.0, 0.0, 0.0],\n","        ...\n","    ]\n",")\n","\n","cycle = Data(\n","    x=...\n","    edge_index=...dense_to_sparse(...)...,\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Task 1.2\n"," Implement binary tree with 7 nodes over three levels directly constructing the edge_index.:\n","    0\n","  1   2\n"," 3 4 5 6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tree = Data(\n","    x=...,\n","    edge_index=torch.tensor([[0, 1], ...]).T,\n",")"]},{"cell_type":"markdown","metadata":{},"source":[" ## Task 1.3\n"," Convert the implemented PyG graphs to `networkx` graphs and plot them."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch_geometric.utils import to_networkx\n","import networkx as nx\n","\n","nx.draw_kamada_kawai(...)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nx.draw_kamada_kawai(...)"]},{"cell_type":"markdown","metadata":{},"source":[" ## Task 1.4\n"," Have a look at the documentation on [Mini-batches](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#mini-batches).\n","\n"," Batch the two graphs together and plot the batch with networkx. What do you see ?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch = Batch.from_data_list(...)\n","..."]},{"cell_type":"markdown","metadata":{},"source":[" ## Task 1.5\n"," Inspect the properties of the batch.\n"," You can use the `inspect` method of the rich library or a simple `print`.\n"," What do the `batch` and `ptr` attributes do?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import rich\n","rich.inspect(batch)\n","# -> `batch` provides the index for teh feature  matrix of each graph in the feature vector of the batch\n","# -> `ptr` does the same, but with a range"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.6 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"cf1e7457895ee7dafed1f4a11df8662f6860406cb300c73c45b696a5411f164d"}}},"nbformat":4,"nbformat_minor":2}
